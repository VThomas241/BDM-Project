{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDM Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dataclasses import dataclass,field\n",
    "from typing import ClassVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete later proper implementation\n",
    "\n",
    "@dataclass\n",
    "class Dataset():\n",
    "    '''\n",
    "    Dataclass used in finding distinct foods.\n",
    "    :param pathtocsv dataset: The path to csv file.  \n",
    "    '''\n",
    "\n",
    "    name: str = field(init=False)\n",
    "    df: pd.DataFrame = field(init=False)\n",
    "    pathtocsv: str\n",
    "    distinctFoods: dict = field(init=False)\n",
    "\n",
    "    def __init__(self,pathtocsv:str):\n",
    "        self.name = pathtocsv.split('/')[-1]\n",
    "        self.df = pd.read_csv(pathtocsv).dropna()\n",
    "        self.distinctFoods = dict()\n",
    "        DatasetBase.datasets.append(self)\n",
    "\n",
    "        for idx in range(len(self.df)):\n",
    "            row = self.df.iloc[idx]\n",
    "            currentFirstName = row['Item'].split()[0]\n",
    "            if currentFirstName not in self.distinctFoods.keys(): \n",
    "                self.distinctFoods[currentFirstName] = []\n",
    "            self.distinctFoods[currentFirstName].append(idx)\n",
    "\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return 'Dataset<{}>'.format(self.name)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return 'Dataset<{}>'.format(self.name)\n",
    "    \n",
    "\n",
    "class DatasetBase:\n",
    "    datasets: list[Dataset] = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "salesApril = Dataset('./CSV Files/SALES APRIL 23.csv')\n",
    "salesMay = Dataset('./CSV Files/SALES MAY 23.csv')\n",
    "purchaseApril = Dataset('./CSV Files/PURCHASE APRIL 23.csv')\n",
    "purchaseMay = Dataset('./CSV Files/PURCHASE MAY 23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset<SALES APRIL 23.csv>,\n",
       " Dataset<SALES MAY 23.csv>,\n",
       " Dataset<PURCHASE APRIL 23.csv>,\n",
       " Dataset<PURCHASE MAY 23.csv>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetBase.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sl</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ACT SANDROP PB CRUNCHY 100G</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ACT SUNDROP PEANUT BUTTER CREAME</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ACT SUNDROP PEANUT BUTTER CREAM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>337</td>\n",
       "      <td>ACT II GOLDEN SIZZLE 30G</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>553</td>\n",
       "      <td>ACT TOMATO CHILLI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>554</td>\n",
       "      <td>ACT BUTTER</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sl                              Item  Quantity  Amount\n",
       "1      2       ACT SANDROP PB CRUNCHY 100G       3.0   150.0\n",
       "2      3  ACT SUNDROP PEANUT BUTTER CREAME       1.0   250.0\n",
       "3      4   ACT SUNDROP PEANUT BUTTER CREAM       1.0   175.0\n",
       "336  337          ACT II GOLDEN SIZZLE 30G       3.0    30.0\n",
       "552  553                 ACT TOMATO CHILLI       1.0    25.0\n",
       "553  554                        ACT BUTTER       3.0    75.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = DatasetBase.datasets[0].distinctFoods['ACT']\n",
    "DatasetBase.datasets[0].df.iloc[test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_one_item = []\n",
    "\n",
    "for key,value in salesApril.distinctFoods.items():\n",
    "    if len(value)==1:\n",
    "        only_one_item.append((key,value)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('916', [0]),\n",
       " ('ALPH', [4]),\n",
       " ('APPLE', [16]),\n",
       " ('BADHAM', [24]),\n",
       " ('BASIL', [27]),\n",
       " ('BAT', [28]),\n",
       " ('BLACK', [29]),\n",
       " ('BN', [30]),\n",
       " ('BONDA', [31]),\n",
       " ('BOURNVITA', [34]),\n",
       " ('BREAD', [36]),\n",
       " ('BURGER', [49]),\n",
       " ('BUTTERSCOTCH', [53]),\n",
       " ('CANDLE', [75]),\n",
       " ('CARDOMAM', [77]),\n",
       " ('CARROT&', [80]),\n",
       " ('CASHEW', [81]),\n",
       " ('CENTRE', [82]),\n",
       " ('CHERI', [83]),\n",
       " ('CHICKEN', [84]),\n",
       " ('CHILLY', [85]),\n",
       " ('CHOCOLATE', [86]),\n",
       " ('CHURUTU', [87]),\n",
       " ('COCONET', [88]),\n",
       " ('COFFEE', [91]),\n",
       " ('COLD', [92]),\n",
       " ('CONEFETTI', [93]),\n",
       " ('CORNFLAKES', [94]),\n",
       " ('CUT', [97]),\n",
       " ('CUTLET', [98]),\n",
       " ('DATES', [99]),\n",
       " ('GOODLIFE', [109]),\n",
       " ('GRAMBU', [110]),\n",
       " ('GRAPE', [111]),\n",
       " ('JEERAGAM', [126]),\n",
       " ('JILEBI', [127]),\n",
       " ('JOLY', [128]),\n",
       " ('KALKANDOM', [129]),\n",
       " ('KARUVAPATTA', [130]),\n",
       " ('KIDILAN', [142]),\n",
       " ('KISNA', [143]),\n",
       " ('KISSMISS', [144]),\n",
       " ('KOPICO', [160]),\n",
       " ('LADDU', [164]),\n",
       " ('LILLY', [178]),\n",
       " ('MACRONS', [181]),\n",
       " ('MEAT', [208]),\n",
       " ('MENTOS', [209]),\n",
       " ('MERICREAM', [213]),\n",
       " ('MILKMAID', [218]),\n",
       " ('MILKYBAR', [223]),\n",
       " ('MIXED', [227]),\n",
       " ('MIXTURE', [228]),\n",
       " ('MOJOIES', [229]),\n",
       " ('MOMS', [230]),\n",
       " ('MUESLI', [231]),\n",
       " ('NARANJA', [236]),\n",
       " ('NEYYAPPAM', [237]),\n",
       " ('ORBIT', [242]),\n",
       " ('OREO', [243]),\n",
       " ('PALAZHY', [247]),\n",
       " ('PAPPADAM', [251]),\n",
       " ('PARIPPU', [252]),\n",
       " ('PARTY', [255]),\n",
       " ('PEASTARY', [256]),\n",
       " ('PINEAPPLE', [257]),\n",
       " ('PISTA', [258]),\n",
       " ('PP', [265]),\n",
       " ('PUFS', [266]),\n",
       " ('PUNCHIRI', [267]),\n",
       " ('ROASTED', [272]),\n",
       " ('ROUND', [273]),\n",
       " ('ROYAL', [274]),\n",
       " ('SAMOSA', [278]),\n",
       " ('SANTHIGITI', [279]),\n",
       " ('SHARJAH', [281]),\n",
       " ('SIPUP', [282]),\n",
       " ('SLICE', [283]),\n",
       " ('SPANISH', [287]),\n",
       " ('SRA', [289]),\n",
       " ('SUGAR', [291]),\n",
       " ('THAKKOLAM', [307]),\n",
       " ('TIC', [308]),\n",
       " ('TISSUE', [309]),\n",
       " ('TOMATO', [310]),\n",
       " ('TOO', [311]),\n",
       " ('ULLIVADA', [317]),\n",
       " ('UNCLE', [318]),\n",
       " ('UNNIMADURAM', [327]),\n",
       " ('UNNIYAPPAM', [328]),\n",
       " ('UZHUNNUVADA', [329]),\n",
       " ('VADA', [330]),\n",
       " ('VANILLA', [331]),\n",
       " ('VATTAYAPPAM', [332]),\n",
       " ('PUTHUMAS', [338]),\n",
       " ('BOUNTY', [339]),\n",
       " ('KK', [343]),\n",
       " ('AMERICAN', [344]),\n",
       " ('PRAN', [373]),\n",
       " ('POLO', [380]),\n",
       " ('BRITAANNIA', [433]),\n",
       " ('HERSHEYS', [464]),\n",
       " ('LOLLIPUP', [465]),\n",
       " ('GEMS', [474]),\n",
       " ('CORN', [547]),\n",
       " ('ACT-II-CLASSIC', [549]),\n",
       " ('ACT-II-GOLDEN', [550]),\n",
       " ('ACT-II-CHILY', [551]),\n",
       " ('SANDROP', [554]),\n",
       " ('GLUCON-D', [555]),\n",
       " ('SUMERU', [556]),\n",
       " ('DARK', [576]),\n",
       " ('FANTA', [608]),\n",
       " ('THUMS', [612]),\n",
       " ('LIMCA', [613]),\n",
       " ('KINLEY', [614]),\n",
       " ('AVT', [615]),\n",
       " ('TROPICANNA', [619]),\n",
       " ('TROPICAN', [622]),\n",
       " ('MOUNTAIN', [634]),\n",
       " ('MAA', [651]),\n",
       " ('DOUBLE', [658]),\n",
       " ('TATA', [663]),\n",
       " ('TIGER', [664]),\n",
       " ('BAMBINO', [666]),\n",
       " ('SNICKERS', [672]),\n",
       " ('ELITE', [680]),\n",
       " ('WAFER', [692]),\n",
       " ('NANDINI', [742]),\n",
       " ('RADIANT', [751]),\n",
       " ('MARAYOOR', [763]),\n",
       " ('ASSAL', [774])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_one_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinctFoodToCsv(foodDict:dict) -> None:\n",
    "    distinctFood = pd.DataFrame(foodDict['foods'].keys(),columns=['Distinct Brands/Food'])\n",
    "    distinctFood.to_csv('./salesAprilDistinct.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
